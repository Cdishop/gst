---
output: pdf_document
---

Employees often face multiple, conflicting goals as they complete their work day. Core tasks, such as skill acquisition and networking opportunities, projects, and reports flood employee experiences while superficial demands, such as emails, meetings, and phone calls threaten to emerge at any moment. In these environments, how do individuals decide which goal to pursue? What process guides their goal sampling behavior over time? Goal choice theories often evoke utility functions [@keeney1976; @von1982; @steel2006] to explain this operation, such that employees choose goal 'A' over goal 'B' to the extent that 'A' produces greater utility. These explanations are among the most actionable organizational theories due to their concrete predictions [@van1996; @miner1980], but they have largely focused on single, static equations that neglect how the decision process updates and evolves alongide the constraints of the environment [@luce1995; @busemeyer2002]. Goal choice theories across psychology, economics, and sociology largely agree on the necessary function parameters [@steel2006], therefore it is time to move beyond specifying a single equation and build a theory that describes the dynamics of goal choice updating. 

In this paper I unpack goal sampling theory (GST), a theory of goal choice that subsumes prior research and embeds the individual utility function in a framework that makes both competing and complimentary predictions. Its purpose is to extend work by @steel2006 by adding elements that are currently missing in their theory but have been highlighted by other authors as critical aspects of goal choice. That is, utility functions (referred to hereafter as $U$ functions) are used as a starting point to build on and the theory presented here shows how they are only one piece to a larger goal decision framework.

The following paper moves sequentially, rather than presenting the entire theoretical framework upfront, to simplify the equations and clearly specify what each aspect represents. Immediately below, I identify what other researchers have presented as criteria for sound goal-choice theory -- the criteria will be used as a backdrop for the rest of the paper. I then discuss individual components before presenting GST in full.

## Crucial Aspects for Theories of Goal Choice

How employees pursue goals in organizations has been an extensive research stream for many years and so a number of criteria have emerged concerning what components theories of goal choice must cover. First, goal pursuit is a dynamic process and so dynamics must be specified and respresented in the theory [@Neal2017]. This component addresses the transition rules for utility as an individual moves through time. Specifically, there must either be some mechanism relating prior to current utility or argument for why utility is independent of its past at each moment. Second, the theory must discuss the environment [@lord2010self]. The environment is now a core element in goal-choice research [@deshon2005motivated; @unsworth2014multiple] and organizational theory more broadly [@johns2018advances], and the idea stems from the common notion running through much of Simon's writing that to understand human behavior it is necessary to study the structure of goal-relevant objects in the environment [@simonant]. Third, goal choice theories must address how goals are prioritized [@deshon2009clarifying]. Even if an agent can only choose one goal at a time, situations often contain multiple, at times conflicting, goals and so some method of priority is required. Finally, @Neal2017 argue that formal theories are necessary because verbal theories tend to be imprecise, easily misunderstood, or ambiguous with respect to dynamics [@vancouver2018translating]. 

My argument is that temporal motivation theory [TMT; @steel2006] covers some but not all of the aspects listed above. Specifically, it is formal and specifies how individual's prioritize multiple goals but is limited in its dynamics and how it represents the environment. The rest of the paper is devoted to briefly describing TMT and then discussing how it can be extended to cover the criteria. Ultimately this discussion will lead to the full framework, GST, and several discussed implications. 

# Choosing a Goal

Goals refer to internal representations of desired states [@austin1996], and the organizational goal-decision literature is concerned with how employees choose which goal to pursue. This notion is distinct from goal-striving, which describes effort and performance strategies usually in the pursuit of a single goal [for exceptions, see @schmidt2007; @vancouver2010]. Theories of goal choice and decision making are present in economics, psychology, and sociology, and are nicely integrated by @steel2006. Their temporal motivation theory (TMT) incorporates hyperbolic discounting, expectancy theory, cumulative prospect theory, and need theory into an integrated $U$ function that predicts goal choice. The details of those theories are not crucial here, as each delivers a variant of a utility equation, such that:

\begin{equation}
U = f(X_{theory})
\end{equation}
\noindent where $U$ represents utility, or a preference for a certain goal, and $X$ is a set of variables whose formal representation depends on the theory. The set of variables, $X$, is not the focus of this paper so it will only be briefly described here. Core variables in the set include expectancy, valence, and deadline/outcome time. Expectancy refers to a subjective belief about the likelihood of achieving a goal. Valence is how much an individual values the outcome that follows goal attainment, and time in TMT refers to when the outcome is received (how distant the reward is). As stated in @steel2006, many fields use $U$ functions -- meaning some combination of expectancy, valence, and time to reward -- to predict goal choice, so I use $U$ as represented in TMT as a starting point to expand on. 

How does TMT and its representation of $U$ compare against the criteria? The theory is formal, so there is little ambiguity in how the different aspects combine to produce utility (for details on the actual function that describes how expectancy, valence, and time to outcome are combined see the original paper by @steel2006). It also handles goal priority well. An agent who is confronted with multiple, competing goals selects the goal with the greatest utility. That is, if an agent's subjective utility for goal 'A,' as produced by some combination of expectancy, valence, and time to reward, is greater than his subjective utility for 'B,' he decides to act toward goal 'A.' This notion may be somewhat simple but it is nonetheless adequately specified in the theory. 

Where it is limited is in its ability to capture dynamics and the environment [@kanfer2016]. That is, irrespective of how complicated the function of expectancy, valence, and time to reward becomes, dynamics and the environment are left unspecified. It is these two aspects that this paper uses as catalysts to expand on. 


# Dynamic Updating

Beginning with dynamics, utility functions have been labeled as time insensitive, static, and unable to capture dynamic effects [kanfermotivation; @luce1999; @baumeister2016]. @steel2006 respond to calls for a dynamic representation in TMT by formally including time as a variable in their $U$ function such that positive outcomes far removed, compared to those that are close, produce lower utility. Incorporating deadlines is appropriate, but simply including time as a variable does not make the equation dynamic. That is, when the $U$ function incorporates time to reward it is still expressed as:

\begin{equation}
U = f(X_{theory})
\end{equation}
\noindent but a variable, $T$, which is the amount of time a subjective perceives that he has until a deadline occurs and an outcome is rewarded, is incorporated into the set of $X$. Doing so captures subjective time, but it does not represent the process over time. To do so, we can change the equation to acknowledge two assumptions: 1) that $U$ can change over time

\begin{equation}
U_{t}
\end{equation}
\noindent and 2) that $U$ is a function of current variables in the set of $X$:

\begin{equation}
f(X_{theory})_{t}
\end{equation}
\noindent which gives us the following when we combine those ideas:

\begin{equation}
U_{t} = f(X_{theory})_{t}.
\end{equation}
\noindent That is, utility at time four depends on the set of variables in $X$ at time four, but utility at time five can be different from utility at time four.

We now have a description of utility over time, but this representation is still not consistent with what researchers would consider dynamic modeling [@busemeyer2018; @voelkle2015relating]. Utility, as presented above, is memoryless, where any effects at time $t$ disappear and are replaced by new effects at time $t+1$. Dynamic representations account for the past, and there are many empirical examples where prior states carry over into the future. Goal discrepancy states show consistency over time [@deshon2009] reflecting satiated behavior [@simon1956]. State goal orientations demonstrate positive autoregressive effects [@beck2013state]. Expectancies retain self-similarity over time [schmidt2009something] and goal utilities tend to have memory in the sense that they are correlated across time even in periods of known development and change such as adolescents moving through high school [@chouinard2008changes].

We represent states with memory mathematically by using autoregressive terms. The following:

\begin{equation}
U_{(t+1)} = b_0 U_{t}
\end{equation}
\noindent expresses utility dynamically, where $U_{(t+1)}$ is utility at the next time point and $b_0$ represents the coefficient relating current to future utility, which formally models self-similarity [@DeShon2012; @vancouver2012].

**Strengths of Incorporating Dynamics** Adding this dynamic element reveals additional strengths of GST. First, utility now has similarity across time. Prior explanations and models that do not present utility in this way assume that goal choices are independent at each moment and any effects at time $t$ disappear and are replaced by new ones at time $t+1$. Although you can describe processes over time in this way, these explanations amount to no more than compiled snapshots of behavior that miss the continual flow governing the system [@Ilgen2000]. As stated above, it is difficult to find an occasion where the prior behavior of a variable is not important to its own development -- incorporating autoregression presents a more realistic model of utility. 

Models that do not account for the past also imply that utility is unconstrained across time. That is, utility at time $t$ can jump to high or low values at time $t+1$ irrespective of its position at $t$. Although I have not seen a discussion about whether such behavior is possible for utility, it would be inconsistent with how researchers in empirical articles describe the variables in the set of $X$ [@dreher1991; @erez2002]. 

>>**Proposition 1**Utility has self similarity across time, such that a goal's utility at time $t$ is positively related to its value at $t + 1$.

# The Environment

The second extension is to incorporate the environment and thereby satisfy an additional criteria [@simon1992explanation]. By environment, I do not mean individual subjective perceptions concerning workplace aspects such as climate, psychological safety, or leadership, but random, situational stimuli that impinge upon actors [@cappelli1991missing]. This perspective is similar to the notion of shocks in the unfolding model of employee turnover in which discrete situations (e.g., a large company layoff) make some actions more likely than others [@lee1994alternative], to events in affective events theory in which random stimuli, such as a computer crash or a coworker running late, cause changes in employee affect and subsequent behavior patterns [@weissaffective], and to Simon's representation of environment in his simple rules model [@simon1956rational] in which by context he means some arrangement of goal-relevant objects. Applied to this paper, the idea is that the environment constrains which goals are available at any given moment [@neal2017dynamic]. 

Consider a few examples: An employee has a high utility for goal 'A' but is forced to work on goal 'B' by her manager; A co-worker is sick and asks another individual to cover his tasks for the day; Low performance at a neighboring branch requires an individual to put off her current work and help train her fellow employees; A Wi-Fi outage constrains an individual's set of goal options; An email with a provocative subject line draws an individual's attention away from his current goal. These examples are simple but are by no means uncommon, yet they are difficult to represent with only utility. Moreover, they reveal that some environmental constraints are consistent but others are random or difficult to predict. Instantiating this notion into a representation of goal choice, therefore, can be done with likelihoods, where an individual has a probability of choosing a goal at a given moment with respect to the environmental constraints. Stated formally:

\begin{equation}
\Theta_{A} = E * U_{A}
\end{equation}
\noindent where $\Theta_{A}$ represents the likelihood of choosing goal 'A,' which is a function of both the environment, $E$, and the utility of 'A', $U_{A}$. If the environment restricts goal 'A' such that it cannot be sampled, then $E$ would be zero and the likelihood of choosing 'A' would also become zero. Although this is a simple representation of the environment, Meehl (1967) suggested creating simple formulas such as the one presented despite an incomplete understanding of the 'true' function [see also @morgan2015]. We may never be able to adequately capture the environment, but it is important to represent nonetheless. 

**Strengths of Incorporating the Environment** By specifying equation two I reveal several strengths of GST that are missing in prior work. First, prior utility models cannot account for situations like those presented above where context forces an individual to change goals. These models either assume that the environment does not matter or is somehow incorporated into the variables that make up utility (valence, expectancy, deadline time). This second assumption does work occasionally -- if, for example, a government shutdown creates new deadline times -- but it is not amenable to the spectrum of situations described above. 

Second, creating a likelihood function by combining the environment with utility demonstrates GST's focus on probabilistic goal sampling rather than a deterministic choice. Researchers use probabilistic terms to describe valence and expectancy [@vaneerde1996], but prior formulae for choosing goals imply that two choices at different points in time should be identical if the values in the set of $X$ at each are the same. GST, conversely, acknowledges that goal choices may differ from one moment compared to another despite equal utility at both. The environment term, therefore, acts like a mathematical error term and captures the notion of different goal choices despite identical utility across time. Probabilitic models are also increasingly popular because even deterministic systems can create unpredictable behavior [@mitchell2009], GST therefore presents a model consistent with the broader scientific literature. 

>>**Proposition 2**Goal sampling at two time points may be different -- even when utility is exactly the same -- because the environment forces sampling.

Before moving on, it is helpful to reiterate what has been covered so far. With very simple extensions, TMT has been updated to cover additional criteria for goal-choice theories. Dynamics is represented by positing the utility term at $t + 1$ as a function of its value at $t$ and so the notion of state consistency, self similarity, and memory is embodied in the theory. Context is represented by including an additional term and multiplying it by utility so that the theory adequately captures situations in which the environment shuts off or ramps up utility for some goals but not others. 

At this point, I pivot and discuss one more extension that is important for goal choice but not directly tied to one of the four criteria that opened this paper: feedback from choosing a goal [kanfer2016motivation]. Experiences people receive from pursuing goals is thought to be an important aspect underlying which goals they select in the future. When someone experiences performance ambiguity they are more likely to switch and pursue goals where performance feedback is made available [@schmidt2010moderating]. People tend to allocate their time toward goals that provide them with immediate and specific hedonic feelings [@northcraft2011feedback] or where they can receive the most information regarding what goal pursuit ultimately leads to [@neal2017dynamic]. Choosing between an individual versus team goal is somewhat determined by the experiences an individual has with the other team members versus the satisfaction he receives from his individual task [@courtright2015structural]. Finally, when an individual experiences greater positive affect for one goal compared to another his valence and expectancy for that goal tend to increase [@schmidtmotivation]. The theory presented here incorporates these effects through experience sampling, which is described next. 

# Experience Sampling

GST claims that goal experiences, or subjective evaluations of the feedback and rewards received from sampling a goal, combine with utility and the environment to drive future goal sampling. The mechanism by which this happens is drawn from Denrell's (2005; 2007) sampling model of impression formation, where people are more likely to sample (i.e., engage with) others for whom they have positive impressions, but stop sampling anyone for whom they have negative impressions. GST extends this notion to goals and experiences with their outcomes. If an individual receives a subjectively favorable experience from a goal then its utility increases and the individual becomes more likely to sample it again in the future. When goals produce unfavorable outcomes, conversely, individuals stop sampling (with a certain probability). Relating goal sampling to prior experiences not only facilitates a dynamic understanding of the process, but it also captures the classic effects of feedback and reward [@ludvig2011; @dickinson1989; @kerr1975; @rescorla1972; @pinsker1970]. 

A formal representation of utility updating based on its own prior state and the sampling experience is as follows:

\begin{equation}
U_{(t+1)} = b_0 U_{t} + b_1 X_t
\end{equation}
\noindent where $X_t$ represents the experience of a goal at time $t$, $b1$ is the weight relating experience to utility, and all other terms are defined above.

Utility then influences the probability of sampling alongside the constraints of the environment at the next time point ($E_{t+1}$):

\begin{equation}
\Theta_{(t+1)} = E_{t+1} * {\frac {1}{1 + e^{U_{(t+1)}}}}
\end{equation}
\noindent where $\Theta_{(t+1)}$ represents the likelihood of sampling at $t+1$ and all other terms are defined above. I will thoroughly discuss the components of these equations in later sections. What is important here is to recognize that we mathematically represented the following: utility and the goal sampling experience influence utility at the next time point (equation 8), and at this time utility combines with the environment to inform the likelihood of goal sampling (equation 9). 

**Strengths of Incorporating Experience Sampling** Incorporating experience sampling provides two strengths beyond prior work. First, I account for the known, classic effects of feedback and rewards. Second, GST captures goal sampling irrespective of goal completion. There are many examples where individuals can still sample goals even after completing them, but past utility theories overlook these situations by focusing only on behavior leading up to goal completion. These implications, however, can be difficult to see from the equations; I therefore discuss them with examples below.

GST predicts that goal experiences influence future goal sampling. Again, an experience in GST is an individual's subjective evaluation of the feedback or reward that a specific goal sample produces. For example, imagine a professor setting the goal to read 50 pages of a book. After one sample of this goal she receives feedback in (potentially) many forms, such as pay, social acknowledgment from others, or feelings regarding reading itself (e.g., pleasure or exhaustion). GST summarizes her subjective evaluation of this feedback with a single value: the experience. If taking action toward the 'read 50 pages' goal results in a positive experience then the professor is more likely to sample it again in the future. But if doing so produces a negative experience then she has a much lower sampling probability. In GST, therefore, the decision to sample is directly tied to utility and the accumulated prior experiences on which it is based.

>>**Proposition 3**Goal choices at time $t$ are positively related to subjective evaluations of a goal experience at the immediately prior time point $t - 1$, such that individuals are more likely to sample goals that provide a subjectively favorable experience at $t - 1$ but less likely to sample goals that provide a subjectively unfavorable experience at $t - 1$.

Second, GST focuses on global sampling behavior and the mechanism just described applies irrespective of whether or not individuals complete the goal. Rather, goal completion in GST is viewed as another experience of sampling. To continue the example, imagine two situations: one where the professor does *not* complete her goal of reading 50 pages, and a second where she does complete it. Both of these situations are samples of the '50 pages' goal where future sampling depends on her perceptions of the experience feedback at each sample. 

Consider first the situation where she does *not* complete the goal. If she views this sample as negative because she underperforms, then sampling the '50 pages' goal is unlikely moving forward. But if other positive aspects of reading overwhelm the negative underperformance, such as the riveting nature of the material or the tranquility surrounding quiet reading time, then the probability of future sampling is higher.

Turn now to the situation where she does complete the '50 pages' goal. If she views this experience as negative (due to say, exhaustion), then future sampling is lower than if she finds the experience positive (due to completing the goal). GST, therefore, focuses on utility updating and sampling behavior across time due to various experiences regardless of where the individual lies on their 'goal completion' continuum. If an individual terminates a goal by completing it, then it can no longer be sampled in the future. But there are many cases, the 'read 50 pages' being one, where goal completion does not remove the goal; GST captures both of these situations. 

>>**Proposition 4**The mechanism of goal sampling as presented in GST is the same irrespective of whether or not the individual has completed the goal.

# Goal Sampling Theory

I have introduced important components for theories of goal choice. Utility perceptions inform goal preferences in the moment, the environment constrains which goals are available, and prior experiences update goal sampling likelihoods. I discussed each individually to avoid overwhelming the reader with equations, but I now move to the full goal sampling theory and place these aspects into a 'control structure' framework to demonstrate how this process develops over time [@newell1973; @meehl1967].

In GST, goal choices are viewed as opportunities to sample goals. Sampling results in an experience, which can be thought of as an individual's subjective evaluation concerning the feedback or reward it produces for that specific sample. This experience updates utility, which then informs the likelihood of sampling that goal again in the future -- alongside the constraints of the environment. Repeated sampling is likely when prior experiences are positive and unlikely when prior experiences are negative [@denrell2005], such that individuals have a low probability of sampling goals that produced poor outcomes in the past. 

The core elements of the theory, therefore, include experiences, utility, and goal sampling likelihoods. A goal is chosen to the extent that it has a high likelihood and is made available by the environment, its outcomes then produce an experience for the individual, that experience informs utility, and utility, finally, combines with the environment to create the likelihood of sampling that goal again moving forward. This mechanism integrates organizational [@kanfer2016], environmental [@simon1956], sampling [@denrell2005], and decision theory [@steel2006] concepts that provide a fruitful description of goal choices. Theories suffer, however, to the extent that they cannot be expressed mathematically [@Pearl2009], so I now present a precise model that incorporates each component. 

For simplicity, consider one individual and her sampling behavior of a single goal, 'A.' Sampling 'A' produces experiences that, in this case, are assumed to follow a normal distribution. Instantiating GST into a formal model of goal 'A' would be:

\begin{equation}
X_{At} \sim {N}(0,1)
\end{equation}

\begin{equation}
U_{A(t+1)} = 
  \begin{cases}
  b_0 U_{At} + b_1 X_{At}, & \text{if goal 'A' is chosen}\\
  b_0 U_{At}, & \text{otherwise}
  \end{cases}
\end{equation}

\begin{equation}
\Theta_{A(t+1)} = E_{t+1} * {\frac {1}{1 + e^{U_{A(t+1)}}}}
\end{equation}

Beginning with equation 10, $X_{At}$ represents her experience of goal 'A' at time $t$ and is assumed to follow a normal distribution with a mean of zero and standard deviation of one. This representation acknowledges that her experience of goal 'A' can be positive, negative, or neutral. Moving to equation 11, her utility of goal 'A' at time $t+1$ ($U_{A(t+1)}$) is influenced by the experience of goal 'A' (to the degree of $b_1$) but only when she samples 'A.' If she does not, then the experience cannot happen and thus does not influence utility. In both cases, her prior utility influences current utility to the degree of $b_0$. Equation 12 represents her likelihood of sampling goal 'A' at the next time point. The likelihood of sampling goal 'A' ($\Theta_{A}$) at $t+1$ is a function of the environment ($E_{t+1}$) and a power function of utility. If utility for goal 'A' is high, then sampling 'A' is likely to the extent that the environment is amenable to that choice. In GST, this process is assumed to operate across all possible goals in the environment, which means that our example individual would have a utility for each possible goal, and at each moment she would act toward the goal with the highest likelihood. 

Simple mathematical representations are preferred over their complex counterparts [@stewart2012; @miller2009], and the power function, at first, seems unnecessary. I use it here because it has empirical support [@guadagni1983; @yechiam2005], is present in Denrell's original social impression sampling model [-@denrell2005], and can handle negative values that emerge from equation 10.

One of the benefits of formal theories is that we can implement them as computational models to ensure their behavior is appropriate. I programmed equations 10 - 12 into a simple computational model where our example employee chooses between two goals, 'A' and 'B', over 20 time points. Figure one shows her utility for both goals across time. The top of the graph shows which goal she chooses at each time by presenting the letter 'B' or 'A' in boldface. For example, her sequence was 'B,' 'A,' 'B' for the first three time points, respectively. We can see that utility demonstrates self similarity across time due to the autoregressive parameter, $b_0$ (set to 0.3 for both goals) and the data are stationary. Moreover, she chooses the goal that has the greatest utility at each respective time, therefore the framework -- and its instantiation in a computational model -- produces consistent behavior. 

Although utility demonstrates self similarity over time, why do we do see fluctuations in Figure one? These changes are due to her experiences, which are shown with respect to her utility in Figure two. The top panel reveals her experiences and utility across time for goal 'A,' whereas the bottom panel is the same but for goal 'B.' Experiences are bar plots because they are independent: her experience outcome at time seven does not depend on her experience at time two. This figure demonstrates the lag effect of experiences on utility. For example, her experience of goal 'B' at time one is negative (bottom panel), and this drives her utility of goal 'B' down at the next time point. Similarly, she has a positive experience of goal 'A' at time eight (top panel) and this increases her utility of goal 'A' at the next time point. Also notice that she does not receive an experience value (i.e., she does not experience) goal 'A' at time points when she chooses goal 'B' (and vice versa).  

In summary, GST unites the pieces I have discussed throughout this paper and produces reasonable behavior when instantiated as a computational model. Having introduced the theory as a whole, I can now turn to its last few implications, implications that concern utility estimates, their stability, and their reliance on experiences. Specifically, if we think about experiences as being drawn from a distribution (equation 10) then we need to consider how different draws inform utility. I will explain these implications below with examples because, although we gain advantages by specifying the functional form of relationships [@vancouver2018; @mcphee1981], digesting the equations can be difficult without connecting them to the real world. After presenting these last implications and propositions I state the theory's assumptions and then close the paper. 

## Additional Implications

In GST individuals are assumed to have their own, true utility for each goal. Their beliefs about the utility of a goal at any moment is an estimate of this true utility value, and because utility estimates are updated by experiences in GST, individuals may arrive at biased estimates of utility if goal samples produce unrepresentative experiences. There are a host of (potentially unknowable) factors that determine whether goals produce positive or negative experiences, and GST raises the idea that these may create sampling tendencies that, in turn, produce biased estimates of utility. For example, imagine a call center employee with the goal of raising \$1200 over the course of a day [@shantz2009]. This goal has a utility for our employee that is informed by the set of $X$ (e.g., expectancy) and also her sampling experiences. For simplicity, assume that her true utility of the goal 'raise \$1200' is 0.7 and that individual experiences of sampling it are $\sim {N}(0,1)$. Now assume that her first experience is poor (e.g., -0.2). According to GST, she is unlikely to sample it again (unless forced to by the environment) and, in this case, her estimate of -0.2 represents a false negative. This is not a bias stemming from poor judgement or miss-intent, rather it is one of limited information. She only has one sample from which to base her estimate, so the probability of that estimate being representative of actual utility is low, and it is unlikely to be corrected because experiences are directly tied to sampling through their influence on utility. GST therefore predicts that more (rather than less) sampling leads to more accurate utility estimates. 

>>**Proposition 5**Greater goal sampling, compared to limited sampling, produces more accurate estimates of utility.

If we reverse proposition five and consider how utility estimates influence sampling behavior we arrive at the next prediction of GST: negative estimates of utility (or low utility) will be more stable than positive estimates (given no environmental coercion). If experiences are negative than an individual's utility estimate is unlikely to change over time because they stop sampling, whereas positive estimates lead to more sampling and potential utility changes. At any moment, a goal that used to result in favorable experiences could instead produce an unpleasant experience, lower utility, and subsequently reduce the probability of sampling that goal again. Negative utility estimates are therefore characterized by limited sampling and stability, whereas positive utility estimates are characterized by greater sampling and instability (but no greater than allowed by $b_0$). 

>>**Proposition 6**Negative utility estimates are more stable than positive utility estimates because the latter lead to more goal sampling and are therefore suspect to change.

Another implication of GST is that we are more likely to find a greater amount of false negative utility estimates than false positives among people who are free to sample goals. Again, positive experiences produce more sampling, which allows an individual to come to a more accurate representation of the experience distribution for a given goal and the utility it can provide. When sampling does not occur, due to negative experiences, improper utility estimates cannot be corrected over time. False negatives are therefore likely to persist while false positives are not. 

Consider students in a graduate program who each have a goal of analyzing two data sets, and assume all are, at first, freely allowed to sample this goal as they please. After a period of time we would find a distribution of utility estimates among our students and each would have sampled the goal a different number of times. If we then forced every student to sample the 'two data set' goal repeatedly, GST predicts that we would find more cases of people raising their utility estimates than lowering it. This is not to say that there would be more instances of positive utility. Rather, GST predicts a larger proportion of false negatives in the pool of estimates in situations where sampling is tied to utility and no environmental coercion exists (initially). 

To unpack this notion even further, imagine that ten students have true utility estimates of 0 for the 'two data set' goal and all of their experience distributions are also centered about 0. Again, we let the students sample at will for a period of time. Students who initially receive positive experiences sample the goal with greater frequency and subsequently reduce their positive estimate toward 0 as they gather more samples, whereas students with initially poor experiences stop sampling and their estimates remain negative. When we return to force the students to sample this goal, only the negative estimates can change because the students with initially (false) positive estimates have built a large number of samples centered about the true value. 

>>**Proposition 7**There are greater amounts of false negative utility estimates than false positives where individuals are free to sample goals.

The examples used to describe propositions five through seven were technical. Here is a summary example that is less abstract. Imagine an employee who wants to be more friendly and therefore sets a goal to spend 20 minutes casually speaking with people in a neighboring department every other day. His first sample goes well. He felt immersed in the conversation, learned about other employees, found them polite and interesting, and ultimately believes that this sample of the goal "20 minutes of casual speaking" helped him become a bit more friendly. These feelings and outcomes, in sum, represent his experience of this specific sample. When he samples the goal again, however, he does not have a good experience. Instead, he feels that he annoyed the others and came off as a brown nose. This new experience then lowers his belief about the ability of this "casual speaking" goal to make him more friendly. As he continues to sample the goal his utility estimate bounces around across time and his experiences accumulate into an experience distribution. His utility estimate will be more accurate when he converses with other employees many times and builds a large experience distribution, compared to a situation where he only tries the goal once or twice (proposition 5). Moreover, after several bad conversation experiences his utility estimate will be low and he will be unlikely to continue, which means that his utility estimate will not change (proposition 6). Finally, if we expand this example to 100 employees who are free to sample the "conversation" goal we reach proposition 7. GST predicts that, over time, there will be a greater number of employees who falsely believe that the conversation goal is of no utility compared to the number of employees who falsely believe that the conversation goal is of great utility. 

# Assumptions and Caveats

Presenting GST's equations also makes a variety of assumptions clear. First, this process is assumed to operate under conditions when sampling is directly related to utility. In GST, the probability of goal sampling cannot change without immediately prior utility perceptions changing unless the environment forces sampling. There may be some situations, however, where goal sampling is more or less sensitive to utility. In these contexts, where various levels of sensitivity are important, utility can be multiplied by an additional parameter in the likelihood equation. Doing so is an unnecessary complication here, but future work could certainly incorporate this additional parameter when needed. 

Second, goal likelihoods are assumed to follow an exponential choice rule [@luce1959]. As stated, this equation was selected to remain consistent with prior work, but a fruitful area for future research is to determine environments where simpler functions are appropriate.  

A number of assumptions are also embedded in how GST represents experiences. GST assumes constant weighting of experiences on utility across time ($b_1$) and this removes contrast effects. Of course, we could also assume that $b_1$ varies over time and thereby allow for fluctuating weights. Moreover, GST assumes that positive and negative experiences have the same effect on utility, and the implications of breaking this assumption depend on whether we give positive or negative experiences more weight. If positive experiences have a greater influence than negative experiences, then utility bias would be lower than cases where negative experiences have more weight because the former situation favors greater sampling driven by positive experiences and thus more representative estimates. 

In its current form, GST does not capture primacy effects. In some situations, the first experience may be so profound that it determines all subsequent sampling and a formal representation of updating likelihoods is not needed. These first impressions may then subsequently produce self fulfilling prophecies and confirmation bias. These effects should not be seen as irrelevant in GST, but are simply complimentary mechanisms that emphasize different features. 

Finally, GST assumes that experience distributions are independent from goal utility estimates. Return to the 'read 50 pages' goal example. GST claims that experiences from sampling the goal 'read 50 pages' inform utility, and utility influences future sampling. GST does not, however, directly tie utility to the outcome of the sampling experience. That is, the professor's belief about her ability to perform the goal 'read 50 pages' (or other aspects of utility) do not determine whether the sampling experience is positive, negative, or neutral. There are many components, some due to the professor and some not, that cause an experience to be positive or negative, and although GST views these experiences as important for utility updating across time, it does not necessarily make the reverse connection. It will be important for future research to understand when utility informs the distribution of possible experiences and when it does not. 

# Discussion

The main contributions of this article are as follows: (1) It develops a dynamic model of goal sampling by extending work by @steel2006. As discussed throughout this paper, once dynamics is represented in the equations a variety of implications emerge, but the core notion is that utility retains something about itself through time; (2) It presents analytically tractable set of equations that are suitable for computational modeling [@vancouver2018]; (3) The paper establishes a link between several bodies of work, including organizational theory and empirical work on the environment, biased sampling models of impression formation, notions of dynamics and processes over time, and the foundational utility aspects that formed the opening of this paper.

example from sociology
TMT
GST


# Conclusion

GST begins with a value concerning the experience of sampling a goal, a value that summarizes how an individual evaluates goal feedback at that moment. In GST, experiences can be registered irrespective of goal completion, and this captures cases where 1) goal sampling continues even after goal completion and 2) individuals leave and return to goals multiple times before completing them. Embedding experiences into GST also helps align the theory with prominent findings early in psychological research regarding rewards and their effects on choices [@ludvig2011]. After a single sample takes place, the experience informs utility, but it does not do so alone in a static way where prior utility perceptions have no influence on the system. Rather, the prior behavior of utility constrains any future update, which is a simple idea but acknowledges the crucial difference between static and dynamic modeling [@kondrashov2016]. Moreover, relating prior to current utility emphasizes that utility perceptions continue (but potentially without perfect carryover) even when goals remain "unsampled" for a period of time. The likelihood of choosing a goal again in the future is then determined by this updated utility value and the environmental constraints that force or deter sampling. This sampling mechanism provides an explanation for how goal choices update over time and makes several predictions that lend themselves to computational modeling. 


```{r Figure1, fig.cap= "Utility for goals **A** and **B** over time. The letters at the top of the chart indicate which goal she chose at each time."}

# . -----------------------------------------------------------------------


# . -----------------------------------------------------------------------


# . -----------------------------------------------------------------------


# The Comp Model ----------------------------------------------------------

set.seed(3)


experience <- function(){
  
  value <- rnorm(1,0,1)
  return(value)
  
}

time <- 20
b0 <- 0.3
b1 <- 0.3
utility_a_start <- 0.2
utility_b_start <- 0.4


df_matrix <- matrix(, ncol = 8, nrow = time)
counter <- 0

for(i in 1:time){
  counter <- counter + 1
  
  
  
  
  
  
  # first time point --------------------------------------------------------
  
  
  if(i == 1){
    
    # time
    df_matrix[counter, 1] <- i
    # utility for goal A
    df_matrix[counter, 2] <- utility_a_start
    # utility for goal B
    df_matrix[counter, 3] <- utility_b_start
    # likelihood for goal A
    df_matrix[counter, 4] <- 1 / 1 + exp(df_matrix[counter, 2])
    likelihood_a <- df_matrix[counter, 4]
    # likelihood for goal B
    df_matrix[counter, 5] <- 1 / 1 + exp(df_matrix[counter, 3])
    likelihood_b <- df_matrix[counter, 5]
    # Goal choice
    choice <- NULL
    
    if(likelihood_a > likelihood_b){
      choice <- 1
    }else{
      choice <- 2
    }
    
    df_matrix[counter, 6] <- choice
    
    
    # Experience goal A if they choose A
    experience_a_b <- c(0,0)
    
    if(choice == 1){
      experience_a_b[1] <- experience()
    }else{
      experience_a_b[2] <- experience()
    }
    
    # experience for goal A
    df_matrix[counter, 7] <- experience_a_b[1]
    # experience for goal B
    df_matrix[counter, 8] <- experience_a_b[2]
    
    
    
    
    
    
    
    
    # other time points -------------------------------------------------------
    
    
  }else{
    
    
    
    # time
    df_matrix[counter, 1] <- i
    # utility for goal A
    df_matrix[counter, 2] <- b0*df_matrix[counter - 1, 2] + b1*df_matrix[counter - 1, 7]
    # utility for goal B
    df_matrix[counter, 3] <- b0*df_matrix[counter - 1, 3] + b1*df_matrix[counter - 1, 8]
    # likelihood for goal A
    df_matrix[counter, 4] <- 1 / 1 + exp(df_matrix[counter, 2])
    likelihood_a <- df_matrix[counter, 4]
    # likelihood for goal B
    df_matrix[counter, 5] <- 1 / 1 + exp(df_matrix[counter, 3])
    likelihood_b <- df_matrix[counter, 5]
    # Goal choice
    choice <- NULL
    
    if(likelihood_a > likelihood_b){
      choice <- 1
    }else{
      choice <- 2
    }
    
    df_matrix[counter, 6] <- choice
    
    
    # Experience goal A if they choose A
    experience_a_b <- c(0,0)
    
    if(choice == 1){
      experience_a_b[1] <- experience()
    }else{
      experience_a_b[2] <- experience()
    }
    
    # experience for goal A
    df_matrix[counter, 7] <- experience_a_b[1]
    # experience for goal B
    df_matrix[counter, 8] <- experience_a_b[2]
    
    
    
  }
  
  
  
}



# ... ---------------------------------------------------------------------


# ... ---------------------------------------------------------------------


# ... ---------------------------------------------------------------------


# Graphs ------------------------------------------------------------------



library(ggplot2)
library(tidyverse)
library(stringr)
library(stringi)
library(gridExtra)

df <- data.frame(df_matrix)
names(df) <- c('Time', 'Utility_a', 'Utility_b', 'Likelihood_a', 'Likelihood_b', 'Choice', 'Experience_a', 'Experience_b')

df_long <- df %>%
  gather(Utility_a, Utility_b, Likelihood_a, Likelihood_b, Experience_a, Experience_b, key = 'goal_initial', value = 'Utility') %>%
  mutate(Goal = 
           ifelse(goal_initial == 'Utility_a', 'A', 
                  ifelse(goal_initial == 'Utility_b', 'B', 
                         ifelse(goal_initial == 'Likelihood_a', 'A',
                                ifelse(goal_initial == 'Likelihood_b', 'B',
                                       ifelse(goal_initial == 'Experience_a', 'A', 'B'))))), 
  )

df_long$goal_initial <- str_replace(df_long$goal_initial, '_a', '')
df_long$goal_initial <- str_replace(df_long$goal_initial, '_b', '')

df_long <- df_long %>%
  spread(key = goal_initial, value = Utility)

df_long$Choice <- ifelse(df_long$Choice == 1, 'A', 'B')

df_long$Choice <- as.character(df_long$Choice)
df_long$Goal <- as.character(df_long$Goal)


df_text <- df_long %>%
  select(Time, Choice)

use_these <- seq(from = 1, to = 40, by = 2)

df_text <- df_text[use_these, ]
df_text$Utility <- c(rep(0.65, 20))
df_text$Goal <- df_text$Choice

# ... ---------------------------------------------------------------------


# ... ---------------------------------------------------------------------


# ... ---------------------------------------------------------------------


# Goal choice over time above utility ------------------------------------------------


plot1 <- ggplot(df_long, aes(x = Time, y = Utility, linetype = Goal, shape = Goal)) + 
  geom_point() + 
  geom_line() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  geom_text(data = df_text, aes(label = Choice, fontface = 'bold'))


plot1

```




```{r Figure2, fig.cap="The effect of experiences on utility across time."}



# ... ---------------------------------------------------------------------


# ... ---------------------------------------------------------------------


# ... ---------------------------------------------------------------------


# Goal choice over time above utility and experiences ---------------------



# Tidy --------------------------------------------------------------------



df_long_long <- df %>%
  gather(Utility_b, Utility_a, Likelihood_a, Likelihood_b, Experience_a, Experience_b, key = 'variable', value = 'Value') %>%
  mutate(Goal = 
           ifelse(variable == 'Utility_b', 'B',
                  ifelse(variable == 'Likelihood_b', 'B', 
                         ifelse(variable == 'Experience_b', 'B',
                                ifelse(variable == 'Utility_a', 'A',
                                       ifelse(variable == 'Likelihood_a', 'A', 'A'))))))

df_long_long$variable <- str_replace(df_long_long$variable, '_b', '')
df_long_long$variable <- str_replace(df_long_long$variable, '_a', '')


df_wo_l <- df_long_long %>%
  filter(variable != 'Likelihood')

df_utility_a <- df_wo_l %>%
  filter(variable == 'Utility' & Goal == 'A')

df_exp_a <- df_wo_l %>%
  filter(variable == 'Experience' & Goal == 'A')

df_utility_b <- df_wo_l %>%
  filter(variable == 'Utility' & Goal == 'B')

df_exp_b <- df_wo_l %>%
  filter(variable == 'Experience' & Goal == 'B')


# Plots -------------------------------------------------------------------



ue_a <- ggplot() + 
  geom_point(data = df_utility_a, aes(x = Time, y = Value)) + 
  geom_line(data = df_utility_a, aes(x = Time, y = Value)) + 
  geom_bar(data = df_exp_a, stat = 'identity', aes(x = Time, y = Value), fill = 'gray85', color = 'black', alpha = 0.2) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line.y = element_line(colour = "black",),
        axis.line.x = element_blank(),
        axis.text.x = element_blank()) +
  scale_x_continuous(breaks = NULL) + 
  labs(title = 'Goal A') +
  xlab(NULL) +
  annotate('text', x = 2, y = 1.5, label = 'Experiences = ') + 
  annotate('rect', xmin = 4.5, xmax = 5.5, ymin = 1.4, ymax = 1.6, alpha = 0.2, color = 'black', fill = 'gray85') + 
  annotate('text', x = 2, y = 1, label = 'Utility = ') + 
  annotate('segment', x = 4.5, xend = 5.5, y = 1, yend = 1, color = 'black') +
  annotate('pointrange', x = 4.5, y = 1, ymin = 1, ymax = 1, color = 'black', size = 0.2) +
  annotate('pointrange', x = 5.5, y = 1, ymin = 1, ymax = 1, color = 'black', size = 0.2)



ue_b <- ggplot() + 
  geom_point(data = df_utility_b, aes(x = Time, y = Value)) + 
  geom_line(data = df_utility_b, aes(x = Time, y = Value)) + 
  geom_bar(data = df_exp_b, stat = 'identity', aes(x = Time, y = Value), fill = 'gray85', color = 'black', alpha = 0.2) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  labs(title = 'Goal B') 


grid.arrange(ue_a, ue_b)

```
